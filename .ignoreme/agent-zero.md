Transcript


Welcome back everyone. It's time for a
new version of Agent Zero. This one is
called 098 and there is a lot of updates
in this version, but I would like to
focus on four primary things today and
make the video a bit shorter. If you're
interested in what comes next, the next
version will actually be a major
breakpoint in Agent Zero's development.
So, make sure to stay till the end of
the video. A quick disclaimer, Agent
Zero is completely free, open source,
private, local. You can use it for
whatever you want. Visit agent-zero.ai
if you want to learn more about the
framework and all of its features. So,
the first big thing you've probably
already noticed is the change of the UI.
We have completely reworked the chat
interface and we have reworked all the
interfaces around it to match the visual
style.
We paid a lot of attention to clarity
and simplicity. So everything has been
streamlined and made as simple as
possible. The flow of the chat is now
organized into these process groups. I
can show you in a new chat. If I tell
the agent check system health,
it will start a new process group. The
first step is generating which means the
LLM is generating tokens writing
commands
and then it's replaced with another step
terminal execution another step another
reasoning by the LLM and now we will
probably get the final response as there
are no more steps needed.
You can also customize the level of
detail you want to see. The default is
that the actual step is automatically
expanded and is being replaced with the
next step and automatically collapsed.
Or you can see just the list of the
steps or no detail at all leaving you
with only the title of the step that is
currently being executed. Or you can see
everything at all times.
Personally, I find the last step
expanded to be the sweet spot between
seeing enough detail but not being
overwhelmed by all the information. You
can now also customize the width of the
chat for maximum readability.
And just like before, you can enable and
disable utility messages that may or may
not be relevant to you. They go into the
process group along with other steps. We
have also greatly improved the design of
the light mode, including settings and
everything. It is very high contrast, so
it's great to use in bright sunlight.
Another great feature of the new UI I
need to mention
is the message cue. Previously, when you
send another message during the agent's
execution, it would immediately
intervene. The agent would stop what it
was doing and react to the message. Now,
when you send another message, it goes
to Q. I can now press enter to send the
message immediately and it would cause
the intervention. Or I can send
as many messages as I want and they will
be processed one by one when the agent
finishes the original task.
I can also send them immediately, delete
them
or add another including attachments and
everything. Another improvement is in
the file browser where you can now
manipulate and edit files. And in the
home screen of agent zero, we have added
these banners that can be used for
notifications or dashboard like widgets
for example to notify new users when
they don't have their API keys set
properly.
Or you can see the system resources
here. One thing I almost forgot to
mention with this redesign is that none
of the original information is lost.
Every step has step details model where
you can see all of the information, all
of the text generated by the LLM, all of
the call parameters. You can copy
anything. You can see it in raw JSON
mode. And this applies to any step of
any kind. You can also easily copy the
contents or let the texttospech module
to speak them. And this also applies to
responses. If the response contains code
blocks or tables,
you can easily copy the whole table in a
format that's compatible with
spreadsheets, for example. You can now
also see some basic statistics in the
header of the process group like when it
was started, the number of steps the
agent had to take and the total
execution time. This one was very long.
It was code 4.6 6 opus taking 19 steps
to analyze the full change log between
versions 097 and 098 giving me this
summary.
And we added some minor quality of life
improvements like having quick access to
the core features of the framework and
for example requiring confirmation when
deleting chats. So you don't delete your
chats or clear them accidentally, but
you still have the option
to delete them quickly if you want. So
that's it for the UI. I probably forgot
a lot of stuff, but I'm sure you will
figure out. We can now move to the next
major thing and that is skills. Agent
zero is now compatible with cloth skills
standard. We replaced instruments that
we previously had. If you've been around
for a long time with Agent Zero, you
know that we had something very very
similar to skills for over a year now.
Instruments that contained instructions
and executable scripts that lived in the
memory database and that were loaded ad
hoc. So you could have infinite number
of them. But because it was 90% the same
as skills, we decided to replace
instruments with skills to have full
compatibility. So you can import any
cloth skill you want to agent zero now
and your agent will be able to use it.
It's located in settings in the skills
tab. Here you can see the list of
skills. Some of them are pre-built. This
will probably change as I am using the
pre-release version. We will probably
clean it up a little, but you can import
any skill you want by choosing a zip
file with the skill. You can download
that from GitHub and it will be imported
into the list. Then the agent can use
the skill tool to load the skill into
the context window and use it. For
example, I have the agent browser by
Verscell here. So, let's give it a try.
So, let's see. We open New York Times
website using agent browser and take a
screenshot.
So the agent should first load the skill
into the context window.
And now it should use the terminal
to open New York Times
in the playright browser.
And now it should take a screenshot.
Right. And here it is.
There's no need to spend much time
talking about skills. You probably
already know what skills are and what
they can be used for. They cannot fully
replace MCPS and they definitely cannot
fully replace native tools for some
tasks, but they are a great simple and
modular way to extend your agents
capabilities beyond the standard without
needing to dig into the code or any
difficult configuration. Speaking of
extensibility, that brings me to the
third big thing we implemented and that
is Git projects. Now, when you create a
project, you have the option to paste a
Git URL. So, I'm going to take a URL of
a random Git repository completely
unrelated to agent zero as an example.
You can put your GitHub access token in
case it's a private repository. This one
is public. So, I can click clone and
continue. I get a warning that there can
be malicious code in the repository that
can poison your agent. So always be
careful and only clone repositories you
know and trust. So let's start.
And what this does is it creates a
project based on my settings. I didn't
change the name or color or anything. So
I can still do it now.
Let's call it get test and give it a
teal color.
And I can see the git status that the
repository has been cleaned. There are
no changes done yet. I can still specify
my instructions and settings etc.
Important thing this repository was
completely unrelated to agent zero. But
if it was a repository made for agent
zero, meaning if it contained the
agent zero project folder with
instructions, custom agents, tools,
extensions or whatever, they would be
cloned here as well. And this way you or
we can share complete agent zero
projects including tools, extensions,
agents with other users. We are
currently working on a benchmarking
project for example that will contain
various benchmarks for LLMs. So anytime
a new LLM comes out we can run a
benchmark on it inside agent zero on
real world use cases. So that will be a
project you will be able to clone into
your agent zero and try on your own. But
as you can see it works just as well for
any other project outside agent zero. If
you want to start working on something
that's already in Git, you don't need to
create a project and clone it manually,
you can do it in the initialization
step. If you want to communicate back to
the repository, push comets, PRs,
whatever. You can just tell your agent
to do it. The repository is fully cloned
with all the git files. So the agent can
push commits for you. And so the UI,
skills, and git projects are the three
big features of this release, but there
is a ton more happening under the hood.
For example, the communication layer
between the front end and the back end
has been completely reworked into a
websocket system. So we do no more
polling to the back end. We still use
JSON APIs for all the smaller API calls
around the framework.
Now developers also have the option to
create websocket endpoints. We will be
utilizing that in our future
developments. Another thing worth
mentioning is that we have consolidated
every user related file into the agent
zero user directory
including the memory working directory
all the user knowledge and everything.
So previously a lot of this stuff was
scattered around the file system. Some
of that was in the temp folder. Some of
that was in the memory folder in the
agent zero root.
Everything that is relevant to you now
is in the user directory, which
simplifies the backup and restore
process. All you need to do now is back
up the user directory and you should be
good to go. As always, please be careful
when migrating your agent zero data or
updating to the new version. Never
delete your previous container until you
have your files fully migrated and
working in the new one. Also, I don't
think it's a good idea to map a folder
on your host computer to agent zero and
reuse it in another container. That way,
you expose yourself to the risk that one
of your containers will damage the files
and you are left without backup. Always
try first with a fresh container with no
volume binding and simply back up and
restore the data from the previous
instance and test that everything works.
And also the agent is now instructed to
work inside
the work their folder inside AO USR
directory
and the agent can see the contents
of the working directory in a system
prompt. It can be customized here in
agent settings work there. You can
select the working directory where the
agent will spawn new terminals by
default and put files by default. You
can choose whether you want to show the
file structure to the agent.
I currently have only one file there but
let me change this a little bit to
demonstrate.
This is how the agent will be able to
see the structure of the working
directory in a system prompt. We already
had the same for projects. If the chat
was inside a project, agent zero would
by default work in the directory of the
project and would be able to see the
files as well. Now we also have it for
non-p project chats. So this is the
state of the next version that is being
released today. I will append this full
change log generated by agent zero to
the release on GitHub. There is a lot of
changes so you can read through and uh
now let me tell you about something we
are preparing for the next release that
is related to the extensibility system
of agent zero. I'm sorry if the audio
sounds a bit weird in the next section.
I noticed when editing this that my
microphone got completely disynchronized
and I had to glue it all together. So
Agent Zero has always been highly
customizable and extensible and modular.
We have this extension system that runs
more than 75% of the whole agent zero
framework. Everything we develop is
being put into extensions so that it can
be removed later or replaced with
something else. Now we want to push this
one step further and we want to make
everything in the agent zero system
extensible. Currently you can extend
projects, you can extend agents. Both
projects and agents can have their own
tools and extensions and now skills.
Projects can have special agents that
other projects would not have. And you
can also extend the core or the global
scope of agent zero by putting
extensions directly into the Python
extensions folder. that will affect
everything across all projects, all
agents.
Now, we already started working on a
plug-in system that will modularize
everything I just said. You can now have
plugins that will work as an envelope
around agents, extensions, front-end
components, tools, skills, even
configuration,
etc. So in the next version you will be
able to pull a plugin that will for
example replace agent zero's memory
system with a different memory system or
it will enhance your agents with skills
or native tools. It can add UI
components to the front end. So skills
or sorry plugins will have their
dedicated configurations or UI
interfaces for example if they require
some user workflow. The goal is for
agent zero to become not just a tool you
can use but a platform that can be built
upon. So we are planning to create
repositories of plugins and git projects
for agent zero where the community can
share their creations and enhancements
for agent zero. We are going to be
removing all a lot of the core
functionality that's currently inside
agent zero hardcoded like the memory
system or for example maybe theuler or
the mcp system etc and moving them into
plugins so that they can be developed
and updated inside agent zero by users
independently of the core system. This
will give us way more flexibility and it
will allow us to break free from the
update cycle where users have to update
agent zero as a whole. Now you will be
able to update your different plugins,
add them and remove them completely
independently. And this is exactly where
agent zero should be headed to be future
proof. And this is where agent zero
should be different to all of the other
other tools and agents because now the
core of agent zero should be lightweight
and do the minimal job to keep the
system together and working.
And what should define your agent zero
instance? its uh capabilities and use
cases should be plugins and sets of
plugins that you can bundle together and
deploy completely independent on the
development of the core agent zero
system. Okay, I think that's it for this
video. As always, thank you very much
for your time and thank you for being
part of agent zero community. You can
see agent-zero.ai
if you want to find links to our other
socials. If you like what we built,
please consider giving us a star on
GitHub and subscribing to our YouTube
channel. That helps us grow.



Transcript


Hey there. Today will be the first video
on a deep dive series where I'll go
through all of the settings that you can
do on agent zero. So this first video
I'll cover just the first tab and I'll
do a separate video for each of the tabs
cuz as you can see we have a lots of
configurable options here. But today
I'll cover just the first tab which are
the agent settings. So this includes the
default agent configuration and the
different models that we can pick and
also some settings about memory and
speechtoext/exttospech.
And the first thing that we have here in
the agent config is the default agent
profile. So this just defines basically
which prompt folder uh the default agent
will use. This is the top level agent
the orchestrator and it defaults to
agent zero which is the one that it's
already prompted about how it can
delegate to the other agents etc. But we
also have some other preconfigured
agents that come with agent zero. We
have developer, hacker, researcher and
these are often used as subordinate
agents but you can you know set a
different uh profile here for the base
agent. This test agent is just one that
I created because these are just folders
within our docker container. Right? So
here if I go to docker shell uh you see
that in the a zero folder we have this
agents uh directory and if I cd into it
you'll see that we have all of these
agents that we see here. So if I delete
uh test agent that I created myself and
refresh the page, you'll see that in the
settings uh that agent disappeared. So
you can copy the existing agents to you
know create your own with uh its own
prompts and use cases. And here we also
have the knowledge subdirectory. Uh it
defaults to custom and that's at first
the only option that you have but I
created also another uh test folder. And
just like the agents knowledge is a
directory here in the A folder. So if
you go to knowledge and do ls you'll see
that we have default and custom. Default
is just the prepackaged knowledge that
comes with agent zero and custom is uh
the default folder for where you'll add
your knowledge files. So you can add any
markdown file here as your knowledge
base and agent zero will automatically
you know index that and be able to
reference that knowledge. So here you
can uh choose a directory if you create
another one other than custom or you
could leave the default custom one and
just add your knowledge files there. And
below that we can configure the models.
So you'll see that agency row has a
combination of models that it uses to
execute the tasks. So it has a chat
model, a utility model, a web browser
model and an embedding model. The chat
model is the one that you directly
interact with and that's you know the
main orchestrator agent but also the uh
sub agents. Uh if you don't determine a
specific uh model for the sub agents, uh
it use the default chat model. The
utility model is meant to be a smaller
model that's used ad hoc, you know, for
small chores that uh complement the work
that the chat model is doing. So for
instance, the utility model is used to
build the queries for memory search.
That's one of the uses of the utility
model. And we also have the web browser
model which is the model that will use
browser use to interact with the web and
the embedding model which is the one
that will create the embeddings for your
knowledge and the memories and any rag
related uh embeddings that we need. It's
the embedding model that will generate.
So the model settings are pretty similar
but let me start with the chat model
here. Uh we have the model provider and
you see we have a bunch of providers
here. I'm using the free inference from
my stakes in AOT but you can use you
know any provider that you want like
open router or even the local models.
I've already made videos on using Venice
AAI to get the free inference and also
on the local models. I'll leave the
links in the description or somewhere
around here if you're interested in
that. But besides the provider, we of
course have to choose the model name
here. I'm using the open source GLM 4.7.
And here we can also set the base URL.
For most of these uh providers, we don't
need to do that because it's already uh
it already defaults to the right one.
But if we're using an alternative API or
if we're using another OpenAI compatible
API, we can choose this option here,
other OpenAI compatible, and set the
base URL here. Let me switch back to my
free inference here. And we also have
the chat model context length. And you
know, all of the models have their
limits. So you can set something within
the limit of the model, right? you can
set something lower or equal to the
model limit of context and this is what
agency rule try to compact and truncate
to maintain within this uh this length.
So this will include everything like the
chat history system prompt you know the
org uh query results and that's why we
have this context window space for chat
history and here we can configure how
much of this context window will be
available for the chat history uh
itself. So if you want to allocate more
of your context window to the knowledge
files that you added or the memory
search results, you can lower here the
uh context window space for the chat
history. And this will leave, you know,
more free space in the context window
for the uh other things that are
included. And here you can toggle if it
supports vision or not. And this is just
to disable, you know, image attachments
if the model doesn't support it to
prevent an error. So you have to set
this accordingly to the model that
you've picked. You also have some rate
limiting options. So you can set the
limit in requests per minute, uh the
limit in input tokens per minute and the
limit in output tokens. And besides
this, we can also pass in any additional
parameters that are supported by light
LLM. So light LLM is a Python package.
And this is what agency row uses in the
background. So we can add other
parameters here that are not directly
mentioned like temperature uh top g or
num ctx to set the maximum context. And
then we have pretty much the same
settings for the utility model, you
know, the same providers, uh, model
name, base API and rate limiting and
additional parameters. But we don't have
the context length uh, configuration
here
because like I said, the utility model
is for ad hoc, you know, disposable
interactions. So it doesn't need to keep
uh the message history. It's just used
uh when it needs to and then that
session is discarded. And for the web
browser model, we also have uh some of
the same settings, including the use
vision toggle, but I would always
recommend you to use a model that
supports vision for the web browser
model. Otherwise, it won't be able to
understand, you know, the images in the
pages that it visits. But all of the
others are the same except on the web
browser models, we have this HTTP
headers uh field. So here, you can add
any headers that will be included on all
the requests that the browser makes. You
could use this to add, you know, for
instance, the authorization header with
a bearer token for some internal portal
that you have that you want to give
agent zero access to. And here we have
the embedding model. And you'll see
there's a warning, no need to change.
And this is because the default model
that comes here prepackaged with agent
zero is a local model that doesn't add
any cost uh in external providers. And
it works pretty well for its purpose.
But if you absolutely have to, you can
uh change here the provider, pick, you
know, for instance, open AI and use the
OpenAI embedding models. And that brings
us to memory. So this is where you can
configure the agency row memory system.
The first thing that you can do is
change the subdirectory. It defaults to
the /memory folder in the Docker
container, but you can set it to
something else. Maybe you want it in a
different disk if you have an external
disc attached there or some other folder
that you want to uh reference for the
memories. Here you have a shortcut to
open the dashboard. And this will bring
up this um searchable list of memories.
You see it also includes the knowledge.
So this is way for you to visually
search through you know your knowledge
and memories that agency has saved. And
then you can you know discard or edit
the memories manually. And you can
simulate the queries here by just typing
you know something. Then we have auto
recall enabled delayed and AI query
preparation. So auto recall is the
default behavior. It means that it will
try to search for memories based on the
context of the conversation and what
you're saying right now. So this adds a
small amount of time to get to the
response, but it's normally unnoticeable
and I definitely recommend leaving it
enabled because of course it's a lot
more powerful. Right? If you disable
this, you'll have to reference those
memory files directly for it to recall
that. But if you're feeling that it's
slow and you don't want to completely
disable it, you can add memory auto
recall delayed. So this will uh do the
search in parallel in the background and
the results will be added in the next
message. And we also have auto recall AI
query preparation which is what I
mentioned about the utility model you
know preparing a query to search on your
memories. And here we also have auto
recall AI post filtering. This is
basically reranking. So the results of
vector searches not always come in the
right order right the most relevant
stuff might appear below some irrelevant
matches. This post filtering uh will
rerank those. So the most relevant stuff
appear above the last relevant stuff.
Then we have also memory auto recall
interval. So this is how often uh these
memories will be attached again to the
context to you know remind the agent of
this relevant memory. And we can set a
limit in characters for the uh space in
the context window that will be
dedicated to autorecalled memories. Then
we can also set a similarity threshold
here. Lower similarity threshold it will
match more stuff but likely more
irrelevant stuff as well and higher
threshold means it will be more strict
on the matches but it might miss uh some
related files if that's not super clear
that they are related and then because
of that reranking that I mentioned we
have a different number that we can set
for the max memories to search and max
memories to use so agent zero will
differentiate between what is
conversation memories and what is
solutions for past problems that it
faced but they're all just memories in
the same way. So you can define how many
memories to return in the search and how
many of those of course after the
reranking will be used. And then we have
automemorize and automemorize
consolidation which are basically
enabling the agent to uh decide to
create a memory by itself if it thinks
that's something relevant to be
remembered. If you don't enable this, it
will require you to explicitly tell it
to create a memory or create a memory
manually. And the consolidation is to
automatically
um merge similar memories and this will
drastically improve the uh memory
quality over time. Uh this is just so it
doesn't you know create duplicate
memories uh of the same thing in in
different instances. And then you can
set the threshold for you know the
similarity uh that will trigger the
consolidation and treat it as the same
memory. And lastly we have speech here.
So this is for the speech to text and
the text to speech. Right? So we can
select the microphone that it will
default to and we can also define the
speech to text model size. We have some
larger models including some
multilingual ones and these multilingual
models will probably be able to detect
if you speak multiple languages in the
same message but I definitely recommend
you to set a preferred language here and
that you speak to it in this language
and this will drastically reduce the
hallucinations. Then we have the silence
threshold and silence duration and
waiting time out. These are basically
the thresholds to detect uh when you
have stopped speaking. Right? Then we
also have enable kukuro tts which is a
free algo external and server side uh
texttospech model. If you disable this
it will use the uh browser text to
speech which is worst sounding but it's
you know completely local. If you're
okay with using an external server side
text to speech model, you can enable
this and the quality will be a lot
higher. So that's it for the first tab
of agent settings and I'll wrap this
video here cuz it's already getting
quite long. But let me know if you have
uh further questions about any of these
settings, you know, or about uh creating
this custom agents and I can answer you
on the comments or record a specific
video if that's a bigger topic to cover.
So thanks for watching and I'll see you
on the next video. Bye.

Transcript


Welcome back to another Agent Zero
release video. Today we are releasing
version 095 and it contains one great
feature we've been working on for quite
some time and that is secrets
management. This is a crucial feature
for anyone who wants to connect agent
zero with external services because now
the agent can manage your credentials
and other secrets in a secure way
without ever exposing them to the LLM
provider or to the chat interface.
Before we jump to the updates, let me
remind you that Agent Zero is completely
free and open- source system. You can
download it, change it to whatever you
want, use it for whatever you want. It
is being built for you to use it for
free. If you like what we built,
consider joining our community on one of
our social networks. And visit our web
agent-.ai, where you can learn more
about our project. You can learn more
about our AOT token we use to power our
community platform. And you can learn
more about the community platform
itself. You can submit improvement
proposals or upload others if you want
to participate on the development with
your ideas.
And we're currently building a new API
system in collaboration with Venice AI
that would allow our AOT token holders
to use cloud-based AI models for free
privately on Venice AI endpoints with
free daily API credits. So stay tuned
for more updates here. Now back to the
secrets management. When you go to
settings, external services, secrets
management, there are two sections of
variables you can now edit. The first
one is a variable store and these are
nonsensitive variables. Here you can
store any variables for your agent that
are not secret. In my case, that's the
host name and port of my email server
and my testing email address or the URL
to login to my home heating system. The
other section is secret store. And as
you can see, these values are masked.
Secret variables are only visible the
first time you enter them. Once you
save, they are masked
and you will no longer be able to see
them, but you can still update the value
anytime. And these are the actual
sensitive information like the password
for my testing email, the username and
password for my heating system. These
nonsensitive variables are exposed to
the agent and uh the LLM the agent uses
in plain text as you can see them here.
These secret variables are represented
just by their placeholders. The agent
and the LLM and the LLM provider can
never see the raw value of the password.
The agent can of course still use the
password using the placeholder and it is
being replaced inside the framework just
before every tool call. So the agent can
use all of these passwords in all the
tools including code execution tool or
the browser. But it will actually never
see these passwords. And that is also
because we replace the raw value of the
password back to the placeholder if the
password occurs in the code execution
tool output or the browser output or
basically anything that goes into the
chat or the LLM history. We are
automatically scanning for the password
values and masking them back to the
placeholder. In both variables and
secrets, you can use comments starting
with hashtag to give your agent
additional information. What is the
password for? what is this section about
etc. Quick demonstration using the email
example. I will just say check emails on
my testing email. The agent should
understand
because it can see the variables from
the secret store. And here we can see
the code the agent generates. So instead
of using the password in plain text, it
uses a special syntax. So this value
will be automatically replaced with the
actual value of the password without the
agent seeing it.
And here you can see it was able to
download messages from the testing
email. I'm going to do one more test
here. I'm going to include one of the
email addresses that occurred in the
result into my secret store.
I'm going to tell the agent, show me
messages from my test email. Again, this
should demonstrate
how the secret value will be replaced in
the code execution output so that the
LLM cannot see it.
And here it is. This is the output of
the code execution tool checking the
email. And you can see that
the LLM can never get to the raw value
of the secret. And this one is actually
another secret email I defined earlier
here. This is also compatible with the
browser use framework. Browser use has a
secret management of their own. So we
made it compatible and we can share our
secrets with browser use.
So here we can see our agent is passing
the required secrets
and the URL to the browser agent.
Browser agent will open the URL, log me
in and I should be able to see the
temperatures and other information from
my heating system.
All right, here we could see the agent
inputting sensitive data into the login
field. And here we can see
the agent got in. So this way your agent
can connect to all sorts of external
services and API endpoints using
credentials and API keys without you
having to worry about exposing your
passwords to LLM providers in different
countries etc.
This replacement syntax is not only used
for secrets. We now also use it to
include files into the chat which is our
second addition to this version that the
agent can now copy paste messages
without having to rewrite them in full.
This is how it works. If I tell the
agent to tell subordinate agent to write
a long story. Previously the subordinate
agent agent one would write a long story
send it back to agent zero and agent
zero would have to rewrite the whole
message to send it back to me. And uh
you can imagine if you had a chain of
like four or five agents, maybe some
research team, and the agent at the end
of the chain would write five pages of
research paper. All of his superior
agents would have to rewrite the whole
message to send it to their superior and
ultimately to me. But now you probably
noticed that the second instance was
very fast and that was because the agent
could use the include replacement syntax
and it could just include the text file
of the previous message. Every tool
output that is longer than 500
characters is now stored into a text
file in the temp folder under the chats
folder so that the agent can reference
the file without having to see or
rewrite the whole text.
This doesn't only save time and money on
tokens, but it also addresses the
problem that some outputs are simply too
large to fit into the context window of
the agent and such information would be
trimmed down and some of it would be
discarded. This way we can still keep
the full information in the text file
and the agent has the ability to read it
in chunks later or do whatever it needs
to do with the file.
I'm going to go through the rest of the
updates just briefly. We now have a
global configuration field for all like
LLM models. Meaning if there are model
parameters you want to use in all the
models across the board like for example
timeouts you can use it in external
services light global settings and you
can put them here. There is also a link
to lightm documentation on what
parameters are available. Next one,
custom HTTP headers for the browser
agent.
In agent settings, web browser model
HTTP headers. You can specify key value
pairs of additional HTTP headers that
will be sent with every request by the
browser agent. Next one is progressive
web app support. Thanks to one of the
members of our community. Thank you.
Meaning if your browser supports
progressive web apps, you can open the
agent zero front end almost like a
native app on your operating system.
Next one is the support of JSON in extra
model parameters. In settings and
models, there's a box for additional
parameters where you can specify
parameters that are passed directly to
the LLM provider. Some of them require
JSON format like for example here Venice
parameters. So now the handler of these
fields supports for JSON and also
literal depending on whether you use or
don't use quotes.
Next is we have changed the way we
generate ids for files, memories and
other elements inside the system.
Previously, we used longwids, but some
large language models can have problems
repeating long sequences of random
characters. So, that's why we made all
the IDs that are used for memories, chat
files, uh, attachments and everything
much shorter so that LLMs don't have
trouble repeating. The rest of the
updates are technical or bug fixes.
There's no need to demonstrate here.
That's it for today. For the next
version 096, we are working on a memory
dashboard. So you will be able to see
all the memories collected by the agent
and you'll be able to manipulate them.
And we are also working on parallel tool
calling or running jobs in the
background. So as always, thank you very
much for your time. Thank you for being
part of our community and see you next

All